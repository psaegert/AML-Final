{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "import os\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import pickle\r\n",
    "import time\r\n",
    "\r\n",
    "from tqdm.auto import tqdm\r\n",
    "\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from sklearn.model_selection import KFold\r\n",
    "from sklearn.metrics import log_loss, brier_score_loss, accuracy_score, confusion_matrix\r\n",
    "\r\n",
    "import GPy\r\n",
    "import optunity as opt\r\n",
    "import sobol as sb\r\n",
    "\r\n",
    "import scipy.stats as stats\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "retrain = False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "with open('../data/data_train.pt', 'rb') as file:\r\n",
    "    X_train, y_train = pickle.load(file)\r\n",
    "\r\n",
    "print(f'{X_train.shape = }')\r\n",
    "print(f'{y_train.shape = }')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X_train.shape = (2521156, 28)\n",
      "y_train.shape = (2521156, 2)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Parameter Optimization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "RandomForestClassifier_parameters = {\r\n",
    "    'n_jobs': 8,                # use 8 cores\r\n",
    "    'random_state': 20210927    # with the same random state\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "hyperparameter_search_space_boundaries = {\r\n",
    "    'n_estimators': [1, 100],\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cross-Validation: Helper Functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "def scale_hyperparameters(hyperparameters):\r\n",
    "    return np.array([h * (boundaries[1] - boundaries[0]) + boundaries[0] for h, boundaries in zip(hyperparameters, hyperparameter_search_space_boundaries.values())])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "def get_mean_CV_Score(score_function, hyperparameters, y_label):\r\n",
    "    assert y_label in ['hosp', 'death']\r\n",
    "    y_index = 0 if y_label == 'hosp' else 1\r\n",
    "\r\n",
    "    n_estimators, = hyperparameters\r\n",
    "\r\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=20210927)\r\n",
    "\r\n",
    "    log_loss_list = np.empty(5, dtype=np.float64)\r\n",
    "\r\n",
    "    for split_index, (fit_index, val_index) in enumerate(kf.split(X_train)):\r\n",
    "        # create splits\r\n",
    "        X_fit, X_val = X_train[fit_index], X_train[val_index]\r\n",
    "        y_fit, y_val = y_train[fit_index], y_train[val_index]\r\n",
    "\r\n",
    "        # scale features\r\n",
    "        sc_X_fit = StandardScaler()\r\n",
    "        X_fit_scaled = sc_X_fit.fit_transform(X_fit)\r\n",
    "        X_val_scaled = sc_X_fit.transform(X_val)\r\n",
    "\r\n",
    "        # create classifier\r\n",
    "        rfc = RandomForestClassifier(**RandomForestClassifier_parameters, n_estimators=n_estimators)\r\n",
    "\r\n",
    "        # fit\r\n",
    "        rfc.fit(X_fit_scaled, y_fit[:, y_index])\r\n",
    "\r\n",
    "        # evaluate\r\n",
    "        y_pred_proba = rfc.predict_proba(X_val_scaled)\r\n",
    "        log_loss_list[split_index] = score_function(y_val[:, y_index], y_pred_proba[:, 1])\r\n",
    "\r\n",
    "    # also penalize n_estimators\r\n",
    "    return np.mean(log_loss_list) + 1e-5 * np.array(n_estimators)**2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "def expected_improvement(n_blocks, n_coupling_network_hidden_layers, n_coupling_network_hidden_nodes, gp):\r\n",
    "    # compute E(q) and Var(q)\r\n",
    "    E_pred, Var_pred = gp.predict_noiseless(np.array([[n_blocks, n_coupling_network_hidden_layers, n_coupling_network_hidden_nodes]]))\r\n",
    "\r\n",
    "    # compute gamma with the STD(q)\r\n",
    "    γ = (E_best - E_pred) / np.sqrt(Var_pred)\r\n",
    "\r\n",
    "    # return Expected Improvement\r\n",
    "    return (np.sqrt(Var_pred) * (γ * stats.norm.cdf(γ) + stats.norm.pdf(γ)))[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "def initialize_GP(n_samples, progress=0):\r\n",
    "    Q_init = np.empty((n_samples, len(hyperparameter_search_space_boundaries)))\r\n",
    "    E_init = np.empty((n_samples, 1))\r\n",
    "\r\n",
    "    # initialize with sobol sequence between 0 and 1\r\n",
    "    for i in range(n_samples):\r\n",
    "        for j, boundaries in enumerate(hyperparameter_search_space_boundaries.values()):\r\n",
    "            Q_init[i, j] = sb.i4_sobol(len(hyperparameter_search_space_boundaries), i)[0][j]\r\n",
    "\r\n",
    "    # compute scores for the initial hyperparameters\r\n",
    "    for i, hyperparameters in enumerate(Q_init):\r\n",
    "\r\n",
    "        # skip the ones that have already been computed\r\n",
    "        if progress > i:\r\n",
    "            continue\r\n",
    "\r\n",
    "        # scale hyperparameters according to their bounds and convert them to integers\r\n",
    "        hyperparameters_scaled = scale_hyperparameters(hyperparameters).round().astype(int)\r\n",
    "\r\n",
    "        # print the status\r\n",
    "        hyperparameters_dict = {key: hyperparameters_scaled[i] for i, key in enumerate(hyperparameter_search_space_boundaries.keys())}\r\n",
    "        print(f'{i+1}/{len(Q_init)}: {hyperparameters_dict}')\r\n",
    "        time.sleep(0.35)\r\n",
    "        \r\n",
    "        # compute cv score\r\n",
    "        E_init[i, :] = get_mean_CV_Score(log_loss, hyperparameters_scaled)\r\n",
    "        print(f'score: {E_init[i, :]}')\r\n",
    "        progress += 1\r\n",
    "\r\n",
    "        # save checkpoint\r\n",
    "        print('Storing Checkpoint...')\r\n",
    "        with open(f'../../hyperparameter_results/RF.pt', 'wb') as file:\r\n",
    "            pickle.dump((Q_init, E_init), file)\r\n",
    "        with open(f'../../hyperparameter_results/RF_progress.pt', 'wb') as file:\r\n",
    "            pickle.dump(progress, file)\r\n",
    "        print('Stored Checkpoint...')\r\n",
    "\r\n",
    "    return Q_init, E_init"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run Optimization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "initial_n_samples = 8\r\n",
    "additional_n_samples = 24"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "GP, Q, E = {}, {}, {}\r\n",
    "for y_label in ['hosp', 'death']:\r\n",
    "    if retrain:\r\n",
    "\r\n",
    "        # load checkpoint if possible\r\n",
    "        if os.path.isfile('../../hyperparameter_results/RF.pt') and os.path.isfile('../../hyperparameter_results/RF_progress.pt'):\r\n",
    "            print('Loading Checkpoint...')\r\n",
    "            with open('../../hyperparameter_results/RF.pt', 'rb') as file:\r\n",
    "                Q[y_label], E[y_label] = pickle.load(file)\r\n",
    "            with open('../../hyperparameter_results/RF_progress.pt', 'rb') as file:\r\n",
    "                progress = pickle.load(file)\r\n",
    "            print('Loaded Checkpoint')\r\n",
    "        else:\r\n",
    "            progress = 0\r\n",
    "\r\n",
    "        # if not all initial hyperparameters have been tested, continue testing them\r\n",
    "        if progress < initial_n_samples:\r\n",
    "            print(f\"Initializing GP...\")\r\n",
    "            time.sleep(0.3)\r\n",
    "            Q[y_label], E[y_label] = initialize_GP(initial_n_samples, progress=progress)\r\n",
    "            progress = initial_n_samples\r\n",
    "\r\n",
    "        # main GP training loop\r\n",
    "        print('Training GP...')\r\n",
    "        for k in range(progress - initial_n_samples, additional_n_samples):\r\n",
    "            # train Gaussian Process\r\n",
    "            GP = GPy.models.GPRegression(Q[y_label], E[y_label], kernel=GPy.kern.Matern52(1))\r\n",
    "            GP.optimize(messages=False)\r\n",
    "\r\n",
    "            # determine E_best (minimum value of E)\r\n",
    "            E_best = np.min(E[y_label])\r\n",
    "\r\n",
    "            # determine q_new (q with maximum expected improvement)\r\n",
    "            optimizer_output = opt.maximize(\r\n",
    "                lambda **kwargs: expected_improvement(gp=GP, **kwargs),\r\n",
    "                **{k: [0, 1] for k in hyperparameter_search_space_boundaries.keys()}\r\n",
    "            )[0]\r\n",
    "\r\n",
    "            # extract and scale new 'optimal' hyperparameters\r\n",
    "            q_new = np.array([optimizer_output[k] for k in hyperparameter_search_space_boundaries.keys()]).ravel()\r\n",
    "            q_new_scaled = scale_hyperparameters(q_new).round().astype(int)\r\n",
    "\r\n",
    "            # only for integer values: if the new hyperparameters have already been tested, the algorithm converged\r\n",
    "            for q in Q[y_label]:\r\n",
    "                if (q_new == q).all():\r\n",
    "                    print('GP Converged early.')\r\n",
    "                    break\r\n",
    "\r\n",
    "            # print status\r\n",
    "            hyperparameters_dict = {key: q_new_scaled[i] for i, key in enumerate(hyperparameter_search_space_boundaries.keys())}\r\n",
    "            print(f'{k+1}/{additional_n_samples}: {hyperparameters_dict}')\r\n",
    "            time.sleep(0.3)\r\n",
    "\r\n",
    "            # add q_new to the training set Q\r\n",
    "            Q[y_label] = np.vstack((Q[y_label], q_new))\r\n",
    "\r\n",
    "            # add value to E\r\n",
    "            E[y_label] = np.vstack((E[y_label], get_mean_CV_Score(log_loss, q_new_scaled).reshape(-1, 1)))\r\n",
    "            print(f'score: {E[y_label][-1, :]}')\r\n",
    "\r\n",
    "            # save checkpoint\r\n",
    "            progress += 1\r\n",
    "            print('Storing Checkpoint...')\r\n",
    "            with open(f'../../hyperparameter_results/RF.pt', 'wb') as file:\r\n",
    "                pickle.dump((Q[y_label], E[y_label]), file)\r\n",
    "            with open(f'../../hyperparameter_results/RF_progress.pt', 'wb') as file:\r\n",
    "                pickle.dump(progress, file)\r\n",
    "            print('Stored Checkpoint...')\r\n",
    "    else:\r\n",
    "        print(f'Loading Results ({y_label})...')\r\n",
    "        with open(f'../hyperparameter_results/RF_{y_label}.pt', 'rb') as file:\r\n",
    "            Q[y_label], E[y_label] = pickle.load(file)\r\n",
    "        print(f'Loaded Results ({y_label})')\r\n",
    "\r\n",
    "    GP[y_label] = GPy.models.GPRegression(Q[y_label], E[y_label], kernel=GPy.kern.Matern52(1))\r\n",
    "    GP[y_label].optimize(messages=False);"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Initializing GP...\n",
      "1/8: {'n_estimators': 1}\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "get_mean_CV_Score() missing 1 required positional argument: 'y_label'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-0da2a5417151>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Initializing GP...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0mQ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_label\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mE\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_label\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minitialize_GP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitial_n_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprogress\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m             \u001b[0mprogress\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minitial_n_samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-ed480392ae38>\u001b[0m in \u001b[0;36minitialize_GP\u001b[1;34m(n_samples, progress)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;31m# compute cv score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mE_init\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_mean_CV_Score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhyperparameters_scaled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'score: {E_init[i, :]}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mprogress\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: get_mean_CV_Score() missing 1 required positional argument: 'y_label'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GP-Prediction"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n_estimators_linspace = np.linspace(np.min(hyperparameter_search_space['n_estimators']) * 0.9, np.max(hyperparameter_search_space['n_estimators']) * 1.1, 1000)\r\n",
    "\r\n",
    "# GP_predicted_log_loss_mean, GP_predicted_log_loss_std = {}, {}\r\n",
    "# for y_label in ['hosp', 'death']:\r\n",
    "#     GP_predicted_log_loss_mean[y_label], GP_predicted_log_loss_var = GP[y_label].predict_noiseless(n_estimators_linspace.reshape(-1, 1))\r\n",
    "#     GP_predicted_log_loss_std[y_label] = np.sqrt(GP_predicted_log_loss_var)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'hyperparameter_search_space' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-a3e094534ea1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mn_estimators_linspace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhyperparameter_search_space\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'n_estimators'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhyperparameter_search_space\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'n_estimators'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m1.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# GP_predicted_log_loss_mean, GP_predicted_log_loss_std = {}, {}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# for y_label in ['hosp', 'death']:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#     GP_predicted_log_loss_mean[y_label], GP_predicted_log_loss_var = GP[y_label].predict_noiseless(n_estimators_linspace.reshape(-1, 1))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hyperparameter_search_space' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Find 'Best' Hyperparameter"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# def GP_log_loss_upper_confidence_bound(n_estimators, gp):\r\n",
    "#     mean, var = gp.predict_noiseless(np.array([[n_estimators]]))\r\n",
    "#     return mean + np.sqrt(var)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# GP_best_hyperparameter_prediction = {}\r\n",
    "# for y_label in ['hosp', 'death']:\r\n",
    "#     GP_best_hyperparameter_prediction[y_label] = opt.minimize(\r\n",
    "#         lambda **kwargs: GP_log_loss_upper_confidence_bound(gp=GP[y_label], **kwargs),\r\n",
    "#         n_estimators=hyperparameter_search_space_boundaries['n_estimators']\r\n",
    "#     )[0]\r\n",
    "\r\n",
    "# hyperparameter_best_upper_confidence_bound = {\r\n",
    "#     y_label: {\r\n",
    "#         'n_estimators': np.exp(GP_best_hyperparameter_prediction[y_label]['n_estimators'])\r\n",
    "#     }\r\n",
    "#     for y_label in ['hosp', 'death']\r\n",
    "# }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GP-Crossvalidation Results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(30, 9))\r\n",
    "\r\n",
    "for i, y_label in enumerate(['hosp', 'death']):\r\n",
    "    axes[i].scatter(Q[y_label], np.array(E[y_label]), color='tab:blue')\r\n",
    "    print(np.array(E[y_label]) + 1e-5 * np.array(Q[y_label])**2)\r\n",
    "    # axes[i].scatter(np.exp(Q[y_label][10:, 0]), E[y_label][10:, 0], color='tab:blue', label='Trained GP')\r\n",
    "\r\n",
    "    # axes[i].plot(n_estimators_linspace, GP_predicted_log_loss_mean[y_label][:, 0], color='black', alpha=0.5, label=r'Predicted Log Loss by GP ($\\pm$ STD)')\r\n",
    "    # axes[i].fill_between(n_estimators_linspace, GP_predicted_log_loss_mean[y_label][:, 0] - GP_predicted_log_loss_std[y_label][:, 0], GP_predicted_log_loss_mean[y_label][:, 0] + GP_predicted_log_loss_std[y_label][:, 0], color='black', alpha=0.2)\r\n",
    "\r\n",
    "    # axes[i].axvline(hyperparameter_best_upper_confidence_bound[y_label]['n_estimators'], color='tab:green', label=r'$N_{\\mathrm{est.}}$ =' + f' {np.round(hyperparameter_best_upper_confidence_bound[y_label][\"n_estimators\"], 3)} (Best Upper Confidence Bound)')\r\n",
    "\r\n",
    "    axes[i].set_xscale('log'); axes[i].set_xlim(np.min(n_estimators_linspace), np.max(n_estimators_linspace))\r\n",
    "    axes[i].set_xlabel('n_estimators'); axes[i].set_ylabel('Log Loss (Binary Crossentropy)'); axes[i].set_title(f'RF Hyperparameter Optimization ({y_label})')\r\n",
    "    # axes[i].legend();"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'Q' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-943802cdeaa9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_label\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'hosp'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'death'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_label\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mE\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_label\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'tab:blue'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mE\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_label\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1e-5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_label\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# axes[i].scatter(np.exp(Q[y_label][10:, 0]), E[y_label][10:, 0], color='tab:blue', label='Trained GP')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Q' is not defined"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABrcAAAIMCAYAAABfSfdDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAe9ElEQVR4nO3dX6jn913n8de7GaNQawvOLEhmNAGnW2e7QruH0KUXFtpdJrmYudCVDBSthM7NRty1CBGlSryqZRWE+GfEEi3YGHshA47kQiMFMSWndDc0KZEhus1EIWObzU1pY3bfe3GOy9njJOeXmd/3nPM+eTxg4Px+vy/n9774cGbe8zy/36+6OwAAAAAAADDB2w56AAAAAAAAAFiVuAUAAAAAAMAY4hYAAAAAAABjiFsAAAAAAACMIW4BAAAAAAAwhrgFAAAAAADAGHvGrar6TFW9VFVfeZ3Hq6p+o6quVtXTVfX+9Y8JAADABHZIAABgaau8cuuRJGff4PF7kpze/nMxyW/d+lgAAAAM9UjskAAAwIL2jFvd/YUk33iDS84n+YPe8mSSd1XV961rQAAAAOawQwIAAEtbx2du3ZHkhR23r23fBwAAALvZIQEAgFtybD+frKouZuttJ/L2t7/9373nPe/Zz6cHAAAW9KUvfekfu/vEQc/B0WGHBACAo+tWdsh1xK0Xk5zacfvk9n3/QndfSnIpSTY2Nnpzc3MNTw8AABwGVfU/D3oGRrBDAgAAt7RDruNtCS8n+Yna8oEkr3T3P6zh+wIAAHD02CEBAIBbsucrt6rqc0k+lOR4VV1L8ktJviNJuvu3k1xJcm+Sq0m+meSnlhoWAACAw80OCQAALG3PuNXdF/Z4vJP857VNBAAAwFh2SAAAYGnreFtCAAAAAAAA2BfiFgAAAAAAAGOIWwAAAAAAAIwhbgEAAAAAADCGuAUAAAAAAMAY4hYAAAAAAABjiFsAAAAAAACMIW4BAAAAAAAwhrgFAAAAAADAGOIWAAAAAAAAY4hbAAAAAAAAjCFuAQAAAAAAMIa4BQAAAAAAwBjiFgAAAAAAAGOIWwAAAAAAAIwhbgEAAAAAADCGuAUAAAAAAMAY4hYAAAAAAABjiFsAAAAAAACMIW4BAAAAAAAwhrgFAAAAAADAGOIWAAAAAAAAY4hbAAAAAAAAjCFuAQAAAAAAMIa4BQAAAAAAwBjiFgAAAAAAAGOIWwAAAAAAAIwhbgEAAAAAADCGuAUAAAAAAMAY4hYAAAAAAABjiFsAAAAAAACMIW4BAAAAAAAwhrgFAAAAAADAGOIWAAAAAAAAY4hbAAAAAAAAjCFuAQAAAAAAMIa4BQAAAAAAwBjiFgAAAAAAAGOIWwAAAAAAAIwhbgEAAAAAADCGuAUAAAAAAMAY4hYAAAAAAABjiFsAAAAAAACMIW4BAAAAAAAwhrgFAAAAAADAGOIWAAAAAAAAY4hbAAAAAAAAjCFuAQAAAAAAMIa4BQAAAAAAwBjiFgAAAAAAAGOIWwAAAAAAAIwhbgEAAAAAADCGuAUAAAAAAMAY4hYAAAAAAABjiFsAAAAAAACMIW4BAAAAAAAwhrgFAAAAAADAGOIWAAAAAAAAY4hbAAAAAAAAjCFuAQAAAAAAMIa4BQAAAAAAwBjiFgAAAAAAAGOIWwAAAAAAAIwhbgEAAAAAADCGuAUAAAAAAMAY4hYAAAAAAABjiFsAAAAAAACMIW4BAAAAAAAwhrgFAAAAAADAGOIWAAAAAAAAY4hbAAAAAAAAjCFuAQAAAAAAMIa4BQAAAAAAwBjiFgAAAAAAAGOIWwAAAAAAAIwhbgEAAAAAADCGuAUAAAAAAMAY4hYAAAAAAABjiFsAAAAAAACMIW4BAAAAAAAwhrgFAAAAAADAGOIWAAAAAAAAY4hbAAAAAAAAjCFuAQAAAAAAMIa4BQAAAAAAwBjiFgAAAAAAAGOIWwAAAAAAAIwhbgEAAAAAADCGuAUAAAAAAMAYK8WtqjpbVc9V1dWqevAGj39/VT1RVV+uqqer6t71jwoAAMAEdkgAAGBJe8atqrotycNJ7klyJsmFqjqz67JfTPJYd78vyX1JfnPdgwIAAHD42SEBAIClrfLKrbuTXO3u57v71SSPJjm/65pO8j3bX78zyd+vb0QAAAAGsUMCAACLWiVu3ZHkhR23r23ft9MvJ/loVV1LciXJT9/oG1XVxararKrN69ev38S4AAAAHHJ2SAAAYFErfebWCi4keaS7Tya5N8lnq+pffO/uvtTdG929ceLEiTU9NQAAAMPYIQEAgJu2Stx6McmpHbdPbt+30/1JHkuS7v7rJN+V5Pg6BgQAAGAUOyQAALCoVeLWU0lOV9VdVXV7tj7s9/Kua76W5MNJUlU/lK3FxHtGAAAAvPXYIQEAgEXtGbe6+7UkDyR5PMlXkzzW3c9U1UNVdW77sk8k+XhV/Y8kn0vyse7upYYGAADgcLJDAgAASzu2ykXdfSVbH/K7875P7vj62SQfXO9oAAAATGSHBAAAlrTK2xICAAAAAADAoSBuAQAAAAAAMIa4BQAAAAAAwBjiFgAAAAAAAGOIWwAAAAAAAIwhbgEAAAAAADCGuAUAAAAAAMAY4hYAAAAAAABjiFsAAAAAAACMIW4BAAAAAAAwhrgFAAAAAADAGOIWAAAAAAAAY4hbAAAAAAAAjCFuAQAAAAAAMIa4BQAAAAAAwBjiFgAAAAAAAGOIWwAAAAAAAIwhbgEAAAAAADCGuAUAAAAAAMAY4hYAAAAAAABjiFsAAAAAAACMIW4BAAAAAAAwhrgFAAAAAADAGOIWAAAAAAAAY4hbAAAAAAAAjCFuAQAAAAAAMIa4BQAAAAAAwBjiFgAAAAAAAGOIWwAAAAAAAIwhbgEAAAAAADCGuAUAAAAAAMAY4hYAAAAAAABjiFsAAAAAAACMIW4BAAAAAAAwhrgFAAAAAADAGOIWAAAAAAAAY4hbAAAAAAAAjCFuAQAAAAAAMIa4BQAAAAAAwBjiFgAAAAAAAGOIWwAAAAAAAIwhbgEAAAAAADCGuAUAAAAAAMAY4hYAAAAAAABjiFsAAAAAAACMIW4BAAAAAAAwhrgFAAAAAADAGOIWAAAAAAAAY4hbAAAAAAAAjCFuAQAAAAAAMIa4BQAAAAAAwBjiFgAAAAAAAGOIWwAAAAAAAIwhbgEAAAAAADCGuAUAAAAAAMAY4hYAAAAAAABjiFsAAAAAAACMIW4BAAAAAAAwhrgFAAAAAADAGOIWAAAAAAAAY4hbAAAAAAAAjCFuAQAAAAAAMIa4BQAAAAAAwBjiFgAAAAAAAGOIWwAAAAAAAIwhbgEAAAAAADCGuAUAAAAAAMAY4hYAAAAAAABjiFsAAAAAAACMIW4BAAAAAAAwhrgFAAAAAADAGOIWAAAAAAAAY4hbAAAAAAAAjCFuAQAAAAAAMIa4BQAAAAAAwBjiFgAAAAAAAGOIWwAAAAAAAIwhbgEAAAAAADCGuAUAAAAAAMAY4hYAAAAAAABjiFsAAAAAAACMIW4BAAAAAAAwhrgFAAAAAADAGOIWAAAAAAAAY4hbAAAAAAAAjCFuAQAAAAAAMIa4BQAAAAAAwBjiFgAAAAAAAGOIWwAAAAAAAIyxUtyqqrNV9VxVXa2qB1/nmh+vqmer6pmq+sP1jgkAAMAUdkgAAGBJx/a6oKpuS/Jwkv+Q5FqSp6rqcnc/u+Oa00l+PskHu/vlqvpXSw0MAADA4WWHBAAAlrbKK7fuTnK1u5/v7leTPJrk/K5rPp7k4e5+OUm6+6X1jgkAAMAQdkgAAGBRq8StO5K8sOP2te37dnp3kndX1V9V1ZNVdfZG36iqLlbVZlVtXr9+/eYmBgAA4DCzQwIAAIta6TO3VnAsyekkH0pyIcnvVtW7dl/U3Ze6e6O7N06cOLGmpwYAAGAYOyQAAHDTVolbLyY5teP2ye37drqW5HJ3/1N3/22Sv8nWogIAAMBbix0SAABY1Cpx66kkp6vqrqq6Pcl9SS7vuuZPsvUbd6mq49l6i4nn1zcmAAAAQ9ghAQCARe0Zt7r7tSQPJHk8yVeTPNbdz1TVQ1V1bvuyx5N8vaqeTfJEkp/r7q8vNTQAAACHkx0SAABYWnX3gTzxxsZGb25uHshzAwAA61dVX+rujYOeg6PJDgkAAEfLreyQq7wtIQAAAAAAABwK4hYAAAAAAABjiFsAAAAAAACMIW4BAAAAAAAwhrgFAAAAAADAGOIWAAAAAAAAY4hbAAAAAAAAjCFuAQAAAAAAMIa4BQAAAAAAwBjiFgAAAAAAAGOIWwAAAAAAAIwhbgEAAAAAADCGuAUAAAAAAMAY4hYAAAAAAABjiFsAAAAAAACMIW4BAAAAAAAwhrgFAAAAAADAGOIWAAAAAAAAY4hbAAAAAAAAjCFuAQAAAAAAMIa4BQAAAAAAwBjiFgAAAAAAAGOIWwAAAAAAAIwhbgEAAAAAADCGuAUAAAAAAMAY4hYAAAAAAABjiFsAAAAAAACMIW4BAAAAAAAwhrgFAAAAAADAGOIWAAAAAAAAY4hbAAAAAAAAjCFuAQAAAAAAMIa4BQAAAAAAwBjiFgAAAAAAAGOIWwAAAAAAAIwhbgEAAAAAADCGuAUAAAAAAMAY4hYAAAAAAABjiFsAAAAAAACMIW4BAAAAAAAwhrgFAAAAAADAGOIWAAAAAAAAY4hbAAAAAAAAjCFuAQAAAAAAMIa4BQAAAAAAwBjiFgAAAAAAAGOIWwAAAAAAAIwhbgEAAAAAADCGuAUAAAAAAMAY4hYAAAAAAABjiFsAAAAAAACMIW4BAAAAAAAwhrgFAAAAAADAGOIWAAAAAAAAY4hbAAAAAAAAjCFuAQAAAAAAMIa4BQAAAAAAwBjiFgAAAAAAAGOIWwAAAAAAAIwhbgEAAAAAADCGuAUAAAAAAMAY4hYAAAAAAABjiFsAAAAAAACMIW4BAAAAAAAwhrgFAAAAAADAGOIWAAAAAAAAY4hbAAAAAAAAjCFuAQAAAAAAMIa4BQAAAAAAwBjiFgAAAAAAAGOIWwAAAAAAAIwhbgEAAAAAADCGuAUAAAAAAMAY4hYAAAAAAABjiFsAAAAAAACMIW4BAAAAAAAwhrgFAAAAAADAGOIWAAAAAAAAY4hbAAAAAAAAjCFuAQAAAAAAMIa4BQAAAAAAwBjiFgAAAAAAAGOIWwAAAAAAAIwhbgEAAAAAADCGuAUAAAAAAMAY4hYAAAAAAABjiFsAAAAAAACMIW4BAAAAAAAwhrgFAAAAAADAGCvFrao6W1XPVdXVqnrwDa770arqqtpY34gAAABMYocEAACWtGfcqqrbkjyc5J4kZ5JcqKozN7juHUl+JskX1z0kAAAAM9ghAQCApa3yyq27k1zt7ue7+9UkjyY5f4PrfiXJp5J8a43zAQAAMIsdEgAAWNQqceuOJC/suH1t+77/p6ren+RUd//pG32jqrpYVZtVtXn9+vU3PSwAAACHnh0SAABY1EqfufVGquptSX4tySf2ura7L3X3RndvnDhx4lafGgAAgGHskAAAwK1aJW69mOTUjtsnt+/7Z+9I8t4kf1lVf5fkA0ku+0BgAACAtyQ7JAAAsKhV4tZTSU5X1V1VdXuS+5Jc/ucHu/uV7j7e3Xd2951Jnkxyrrs3F5kYAACAw8wOCQAALGrPuNXdryV5IMnjSb6a5LHufqaqHqqqc0sPCAAAwBx2SAAAYGnHVrmou68kubLrvk++zrUfuvWxAAAAmMoOCQAALGmVtyUEAAAAAACAQ0HcAgAAAAAAYAxxCwAAAAAAgDHELQAAAAAAAMYQtwAAAAAAABhD3AIAAAAAAGAMcQsAAAAAAIAxxC0AAAAAAADGELcAAAAAAAAYQ9wCAAAAAABgDHELAAAAAACAMcQtAAAAAAAAxhC3AAAAAAAAGEPcAgAAAAAAYAxxCwAAAAAAgDHELQAAAAAAAMYQtwAAAAAAABhD3AIAAAAAAGAMcQsAAAAAAIAxxC0AAAAAAADGELcAAAAAAAAYQ9wCAAAAAABgDHELAAAAAACAMcQtAAAAAAAAxhC3AAAAAAAAGEPcAgAAAAAAYAxxCwAAAAAAgDHELQAAAAAAAMYQtwAAAAAAABhD3AIAAAAAAGAMcQsAAAAAAIAxxC0AAAAAAADGELcAAAAAAAAYQ9wCAAAAAABgDHELAAAAAACAMcQtAAAAAAAAxhC3AAAAAAAAGEPcAgAAAAAAYAxxCwAAAAAAgDHELQAAAAAAAMYQtwAAAAAAABhD3AIAAAAAAGAMcQsAAAAAAIAxxC0AAAAAAADGELcAAAAAAAAYQ9wCAAAAAABgDHELAAAAAACAMcQtAAAAAAAAxhC3AAAAAAAAGEPcAgAAAAAAYAxxCwAAAAAAgDHELQAAAAAAAMYQtwAAAAAAABhD3AIAAAAAAGAMcQsAAAAAAIAxxC0AAAAAAADGELcAAAAAAAAYQ9wCAAAAAABgDHELAAAAAACAMcQtAAAAAAAAxhC3AAAAAAAAGEPcAgAAAAAAYAxxCwAAAAAAgDHELQAAAAAAAMYQtwAAAAAAABhD3AIAAAAAAGAMcQsAAAAAAIAxxC0AAAAAAADGELcAAAAAAAAYQ9wCAAAAAABgDHELAAAAAACAMcQtAAAAAAAAxhC3AAAAAAAAGEPcAgAAAAAAYAxxCwAAAAAAgDHELQAAAAAAAMYQtwAAAAAAABhD3AIAAAAAAGAMcQsAAAAAAIAxxC0AAAAAAADGELcAAAAAAAAYQ9wCAAAAAABgDHELAAAAAACAMcQtAAAAAAAAxhC3AAAAAAAAGEPcAgAAAAAAYAxxCwAAAAAAgDHELQAAAAAAAMYQtwAAAAAAABhjpbhVVWer6rmqulpVD97g8Z+tqmer6umq+vOq+oH1jwoAAMAEdkgAAGBJe8atqrotycNJ7klyJsmFqjqz67IvJ9no7h9O8vkkv7ruQQEAADj87JAAAMDSVnnl1t1Jrnb38939apJHk5zfeUF3P9Hd39y++WSSk+sdEwAAgCHskAAAwKJWiVt3JHlhx+1r2/e9nvuT/NmNHqiqi1W1WVWb169fX31KAAAAprBDAgAAi1rpM7dWVVUfTbKR5NM3ery7L3X3RndvnDhxYp1PDQAAwDB2SAAA4GYcW+GaF5Oc2nH75PZ9/5+q+kiSX0jyI9397fWMBwAAwDB2SAAAYFGrvHLrqSSnq+quqro9yX1JLu+8oKrel+R3kpzr7pfWPyYAAABD2CEBAIBF7Rm3uvu1JA8keTzJV5M81t3PVNVDVXVu+7JPJ/nuJH9cVf+9qi6/zrcDAADgCLNDAgAAS1vlbQnT3VeSXNl13yd3fP2RNc8FAADAUHZIAABgSau8LSEAAAAAAAAcCuIWAAAAAAAAY4hbAAAAAAAAjCFuAQAAAAAAMIa4BQAAAAAAwBjiFgAAAAAAAGOIWwAAAAAAAIwhbgEAAAAAADCGuAUAAAAAAMAY4hYAAAAAAABjiFsAAAAAAACMIW4BAAAAAAAwhrgFAAAAAADAGOIWAAAAAAAAY4hbAAAAAAAAjCFuAQAAAAAAMIa4BQAAAAAAwBjiFgAAAAAAAGOIWwAAAAAAAIwhbgEAAAAAADCGuAUAAAAAAMAY4hYAAAAAAABjiFsAAAAAAACMIW4BAAAAAAAwhrgFAAAAAADAGOIWAAAAAAAAY4hbAAAAAAAAjCFuAQAAAAAAMIa4BQAAAAAAwBjiFgAAAAAAAGOIWwAAAAAAAIwhbgEAAAAAADCGuAUAAAAAAMAY4hYAAAAAAABjiFsAAAAAAACMIW4BAAAAAAAwhrgFAAAAAADAGOIWAAAAAAAAY4hbAAAAAAAAjCFuAQAAAAAAMIa4BQAAAAAAwBjiFgAAAAAAAGOIWwAAAAAAAIwhbgEAAAAAADCGuAUAAAAAAMAY4hYAAAAAAABjiFsAAAAAAACMIW4BAAAAAAAwhrgFAAAAAADAGOIWAAAAAAAAY4hbAAAAAAAAjCFuAQAAAAAAMIa4BQAAAAAAwBjiFgAAAAAAAGOIWwAAAAAAAIwhbgEAAAAAADCGuAUAAAAAAMAY4hYAAAAAAABjiFsAAAAAAACMIW4BAAAAAAAwhrgFAAAAAADAGOIWAAAAAAAAY4hbAAAAAAAAjCFuAQAAAAAAMIa4BQAAAAAAwBjiFgAAAAAAAGOIWwAAAAAAAIwhbgEAAAAAADCGuAUAAAAAAMAY4hYAAAAAAABjiFsAAAAAAACMIW4BAAAAAAAwhrgFAAAAAADAGOIWAAAAAAAAY4hbAAAAAAAAjCFuAQAAAAAAMIa4BQAAAAAAwBjiFgAAAAAAAGOIWwAAAAAAAIwhbgEAAAAAADCGuAUAAAAAAMAY4hYAAAAAAABjiFsAAAAAAACMIW4BAAAAAAAwhrgFAAAAAADAGOIWAAAAAAAAY4hbAAAAAAAAjCFuAQAAAAAAMMZKcauqzlbVc1V1taoevMHj31lVf7T9+Ber6s61TwoAAMAIdkgAAGBJe8atqrotycNJ7klyJsmFqjqz67L7k7zc3T+Y5NeTfGrdgwIAAHD42SEBAIClrfLKrbuTXO3u57v71SSPJjm/65rzSX5/++vPJ/lwVdX6xgQAAGAIOyQAALCoVeLWHUle2HH72vZ9N7ymu19L8kqS713HgAAAAIxihwQAABZ1bD+frKouJrm4ffPbVfWV/Xx+3lKOJ/nHgx6CI8v5YmnOGEtyvljSvz7oATha7JDsI38/sjRnjCU5XyzJ+WJJN71DrhK3Xkxyasftk9v33eiaa1V1LMk7k3x99zfq7ktJLiVJVW1298bNDA17cb5YkvPF0pwxluR8saSq2jzoGTgU7JCM43yxNGeMJTlfLMn5Ykm3skOu8raETyU5XVV3VdXtSe5LcnnXNZeT/OT21z+W5C+6u292KAAAAMayQwIAAIva85Vb3f1aVT2Q5PEktyX5THc/U1UPJdns7stJfi/JZ6vqapJvZGt5AQAA4C3GDgkAACxtpc/c6u4rSa7suu+TO77+VpL/9Caf+9KbvB7eDOeLJTlfLM0ZY0nOF0tyvkhih2Qk54ulOWMsyfliSc4XS7rp81Xe+QEAAAAAAIApVvnMLQAAAAAAADgUFo9bVXW2qp6rqqtV9eANHv/Oqvqj7ce/WFV3Lj0TR8cK5+tnq+rZqnq6qv68qn7gIOZkpr3O147rfrSquqo29nM+ZlvlfFXVj2//DHumqv5wv2dkthX+jvz+qnqiqr68/ffkvQcxJ/NU1Weq6qWq+srrPF5V9RvbZ+/pqnr/fs/IbHZIlmSHZEl2SJZkh2RpdkiWstQOuWjcqqrbkjyc5J4kZ5JcqKozuy67P8nL3f2DSX49yaeWnImjY8Xz9eUkG939w0k+n+RX93dKplrxfKWq3pHkZ5J8cX8nZLJVzldVnU7y80k+2N3/Jsl/2e85mWvFn2G/mOSx7n5fkvuS/Ob+TslgjyQ5+waP35Pk9Pafi0l+ax9m4oiwQ7IkOyRLskOyJDskS7NDsrBHssAOufQrt+5OcrW7n+/uV5M8muT8rmvOJ/n97a8/n+TDVVULz8XRsOf56u4nuvub2zefTHJyn2dkrlV+fiXJr2TrP1S+tZ/DMd4q5+vjSR7u7peTpLtf2ucZmW2VM9ZJvmf763cm+ft9nI/BuvsLSb7xBpecT/IHveXJJO+qqu/bn+k4AuyQLMkOyZLskCzJDsnS7JAsZqkdcum4dUeSF3bcvrZ93w2v6e7XkryS5HsXnoujYZXztdP9Sf5s0Yk4SvY8X9svkT3V3X+6n4NxJKzy8+vdSd5dVX9VVU9W1Rv9hgvstsoZ++UkH62qa0muJPnp/RmNt4A3+2802MkOyZLskCzJDsmS7JAszQ7JQbqpHfLYYuPAIVJVH02ykeRHDnoWjoaqeluSX0vysQMehaPrWLZejv2hbP3G8Beq6t929/86yKE4Ui4keaS7/1tV/fskn62q93b3/znowQDgoNkhWTc7JPvADsnS7JAcKku/cuvFJKd23D65fd8Nr6mqY9l6SePXF56Lo2GV85Wq+kiSX0hyrru/vU+zMd9e5+sdSd6b5C+r6u+SfCDJZR8IzIpW+fl1Lcnl7v6n7v7bJH+TrUUFVrHKGbs/yWNJ0t1/neS7khzfl+k46lb6Nxq8DjskS7JDsiQ7JEuyQ7I0OyQH6aZ2yKXj1lNJTlfVXVV1e7Y+aO7yrmsuJ/nJ7a9/LMlfdHcvPBdHw57nq6rel+R3srWUeK9h3ow3PF/d/Up3H+/uO7v7zmy9H/+57t48mHEZZpW/H/8kW79xl6o6nq23mHh+H2dktlXO2NeSfDhJquqHsrWYXN/XKTmqLif5idrygSSvdPc/HPRQjGGHZEl2SJZkh2RJdkiWZofkIN3UDrno2xJ292tV9UCSx5PcluQz3f1MVT2UZLO7Lyf5vWy9hPFqtj5U7L4lZ+LoWPF8fTrJdyf54+3PmP5ad587sKEZY8XzBTdlxfP1eJL/WFXPJvnfSX6uu/1WOitZ8Yx9IsnvVtV/zdYHA3/Mfw6ziqr6XLb+4+T49vvt/1KS70iS7v7tbL3//r1Jrib5ZpKfOphJmcgOyZLskCzJDsmS7JAszQ7JkpbaIcv5AwAAAAAAYIql35YQAAAAAAAA1kbcAgAAAAAAYAxxCwAAAAAAgDHELQAAAAAAAMYQtwAAAAAAABhD3AIAAAAAAGAMcQsAAAAAAIAxxC0AAAAAAADG+L+2qFQ4maU5CQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 2160x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Final Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# scale features\r\n",
    "sc_X_train = StandardScaler()\r\n",
    "X_train_scaled = sc_X_train.fit_transform(X_train)\r\n",
    "\r\n",
    "# create classifier\r\n",
    "rfc = {y_label: RandomForestClassifier(**RandomForestClassifier_parameters, n_estimators=100) for y_label in ['hosp', 'death']}\r\n",
    "\r\n",
    "# fit\r\n",
    "for i, y_label in enumerate(tqdm(['hosp', 'death'])):\r\n",
    "    rfc[y_label].fit(X_train_scaled, y_train[:, i]);"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 2/2 [07:59<00:00, 239.66s/it]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation on Test Set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with open('../data/data_test.pt', 'rb') as file:\r\n",
    "    X_test, y_test = pickle.load(file)\r\n",
    "\r\n",
    "print(f'{X_test.shape = }')\r\n",
    "print(f'{y_test.shape = }')\r\n",
    "\r\n",
    "X_test_scaled = sc_X_train.transform(X_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X_test.shape = (630290, 28)\n",
      "y_test.shape = (630290, 2)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "evaluation_results = {}\r\n",
    "\r\n",
    "for i, y_label in enumerate(['hosp', 'death']):\r\n",
    "    print(f'--- {y_label} ---')\r\n",
    "\r\n",
    "    y_pred_proba = rfc[y_label].predict_proba(X_test_scaled)\r\n",
    "    evaluation_results[y_label] = y_pred_proba\r\n",
    "    y_pred = rfc[y_label].predict(X_test_scaled)\r\n",
    "\r\n",
    "    print(f'binary cross-entropy: {np.round(log_loss(y_test[:, i], y_pred_proba[:, 1]), 4)}')\r\n",
    "    print(f'brier loss: {brier_score_loss(y_test[:, i], y_pred_proba[:, 1]).round(4)}')\r\n",
    "    print(f'accuracy: {accuracy_score(y_test[:, i], y_pred).round(4)}')\r\n",
    "    print('confusion matrix:')\r\n",
    "    print(confusion_matrix(y_test[:, i], y_pred))\r\n",
    "    print()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--- hosp ---\n",
      "binary cross-entropy: 0.3636\n",
      "brier loss: 0.0547\n",
      "accuracy: 0.9343\n",
      "confusion matrix:\n",
      "[[581891   3731]\n",
      " [ 37708   6960]]\n",
      "\n",
      "--- death ---\n",
      "binary cross-entropy: 0.0352\n",
      "brier loss: 0.0093\n",
      "accuracy: 0.9887\n",
      "confusion matrix:\n",
      "[[621176    310]\n",
      " [  6819   1985]]\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with open('../evaluation_results/models/RF.pt', 'wb') as file:\r\n",
    "    pickle.dump(evaluation_results, file)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Observations"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "more false negatives than false positives. Slightly better accuracy than SVC and LR."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "68764fea58fce3debd0ec160882a0d43aa3f505a880da5fb9e1c918b12b71a7c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}