{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import INN\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import log_loss, brier_score_loss, accuracy_score, confusion_matrix\n",
    "\n",
    "import GPy\n",
    "import optunity as opt\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using device: {device}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "retrain = True"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "with open('../../data/data_train.pt', 'rb') as file:\n",
    "    X_train, y_train = pickle.load(file)\n",
    "\n",
    "print(f'{X_train.shape = }')\n",
    "print(f'{y_train.shape = }')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X_train.shape = (2313665, 33)\n",
      "y_train.shape = (2313665, 2)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Parameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "INN_parameters = {\n",
    "    'in_features': X_train.shape[1],\n",
    "    'out_features': y_train.shape[1],\n",
    "    'device': device\n",
    "}\n",
    "\n",
    "loss_weights = {\n",
    "    'bce_factor': 10,\n",
    "    'dvg_factor': 1,\n",
    "    'logdet_factor': 1,\n",
    "    'rcst_factor': 1\n",
    "}\n",
    "\n",
    "lr = 5e-4"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "hyperparameter_search_space_boundaries = {\n",
    "    'n_blocks': [1, 12],\n",
    "    'n_coupling_network_hidden_layers': [1, 5],\n",
    "    'n_coupling_network_hidden_nodes': [4, 512 + 256],\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "n_epochs = 32\n",
    "batch_size = 512"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Helper Functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def scale_hyperparameters(hyperparameters):\n",
    "    return np.array([h * (boundaries[1] - boundaries[0]) + boundaries[0] for h, boundaries in zip(hyperparameters, hyperparameter_search_space_boundaries.values())])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def GP_log_loss_upper_confidence_bound(n_blocks, n_coupling_network_hidden_layers, n_coupling_network_hidden_nodes, gp):\n",
    "    mean, var = gp.predict_noiseless(np.array([[n_blocks, n_coupling_network_hidden_layers, n_coupling_network_hidden_nodes]]))\n",
    "    return mean + np.sqrt(var)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load GP-Results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "print(f'Loading Results ...')\n",
    "with open(f'../../hyperparameter_results/INN.pt', 'rb') as file:\n",
    "    Q, E = pickle.load(file)\n",
    "print(f'Loaded Results')\n",
    "\n",
    "GP = GPy.models.GPRegression(Q, E, kernel=GPy.kern.Matern52(3))\n",
    "GP.optimize(messages=False);"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading Results ...\n",
      "Loaded Results\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Find Best Hyperparameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "hyperparameter_best_upper_confidence_bound = opt.minimize(\n",
    "    lambda **kwargs: GP_log_loss_upper_confidence_bound(gp=GP, **kwargs),\n",
    "    **{k: [0, 1] for k in hyperparameter_search_space_boundaries.keys()}\n",
    ")[0]\n",
    "\n",
    "hyperparameter_best_upper_confidence_bound_scaled = scale_hyperparameters(hyperparameter_best_upper_confidence_bound.values()).round().astype(int)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "best_sampled_hyperparameters = scale_hyperparameters(Q[np.argmin(E)]).round().astype(int)\n",
    "print(f'{best_sampled_hyperparameters=}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "best_sampled_hyperparameters=array([  3,   1, 748])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Final Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "sc_X_train = StandardScaler()\n",
    "X_train_scaled = sc_X_train.fit_transform(X_train)\n",
    "\n",
    "if retrain:\n",
    "    for i in range(5):\n",
    "        # scale features\n",
    "\n",
    "        #create classifier\n",
    "        inn = INN.INN(**INN_parameters, \n",
    "            n_blocks=best_sampled_hyperparameters[0], \n",
    "            coupling_network_layers=[best_sampled_hyperparameters[2]] * best_sampled_hyperparameters[1]\n",
    "        )\n",
    "        inn.train()\n",
    "\n",
    "        X_train_scaled_cuda = torch.Tensor(X_train_scaled).to(device)\n",
    "        y_train_cuda = torch.Tensor(y_train).to(device)\n",
    "\n",
    "        # fit\n",
    "        loss_history = inn.fit(X_train_scaled_cuda, y_train_cuda, \n",
    "            n_epochs=n_epochs,\n",
    "            batch_size=batch_size,\n",
    "            optimizer=Adam(inn.parameters(), lr=lr), \n",
    "            loss_weights=loss_weights,\n",
    "            verbose=1,\n",
    "        );\n",
    "\n",
    "        with open(f'../../evaluation_results/models/INN_{i}.pt', 'wb') as file:\n",
    "            pickle.dump(inn.to('cpu'), file)\n",
    "\n",
    "        with open(f'../../evaluation_results/loss_history/INN_{i}.pt', 'wb') as file:\n",
    "            pickle.dump(loss_history, file)\n",
    "\n",
    "        del inn, X_train_scaled_cuda, y_train_cuda\n",
    "\n",
    "else:\n",
    "    if os.path.exists('../../evaluation_results/models/INN.pt'):\n",
    "        with open('../../evaluation_results/models/INN.pt', 'rb') as file:\n",
    "            inn = pickle.load(file)\n",
    "    if os.path.exists('../../evaluation_results/loss_history/INN.pt'):\n",
    "        with open('../../evaluation_results/loss_history/INN.pt', 'rb') as file:\n",
    "            loss_history = pickle.load(file)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 32/32 [26:04<00:00, 48.88s/it, batch=4517/4518, weighted_loss=-74.899, bce=+0.188, dvg=+7.697, rcst=+0.476, logdet=-84.955]\n",
      "100%|██████████| 32/32 [25:19<00:00, 47.48s/it, batch=4517/4518, weighted_loss=-74.375, bce=+0.163, dvg=+8.384, rcst=+0.508, logdet=-84.900]\n",
      "100%|██████████| 32/32 [24:45<00:00, 46.43s/it, batch=4517/4518, weighted_loss=-74.739, bce=+0.165, dvg=+8.354, rcst=+0.489, logdet=-85.231]\n",
      "100%|██████████| 32/32 [26:18<00:00, 49.32s/it, batch=4517/4518, weighted_loss=-73.860, bce=+0.208, dvg=+8.502, rcst=+0.469, logdet=-84.913]\n",
      "100%|██████████| 32/32 [26:42<00:00, 50.06s/it, batch=4517/4518, weighted_loss=-72.386, bce=+0.169, dvg=+9.753, rcst=+0.478, logdet=-84.303]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "with open('../../data/data_test.pt', 'rb') as file:\n",
    "    X_test, y_test = pickle.load(file)\n",
    "\n",
    "print(f'{X_test.shape = }')\n",
    "print(f'{y_test.shape = }')\n",
    "\n",
    "X_test_scaled = torch.Tensor(sc_X_train.transform(X_test)).to(device)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X_test.shape = (578417, 33)\n",
      "y_test.shape = (578417, 2)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluate"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "evaluation_results = {'hosp': [], 'death': []}\n",
    "\n",
    "for j in range(5):\n",
    "\n",
    "    with open(f'../../evaluation_results/models/INN_{j}.pt', 'rb') as file:\n",
    "        inn = pickle.load(file).to(device)\n",
    "\n",
    "    n_batches = len(X_test) // batch_size\n",
    "    y_proba_pred = np.empty((len(X_test), 2))\n",
    "    for i_batch in tqdm(range(n_batches + 1)):\n",
    "        y_proba_pred[i_batch * batch_size: (i_batch+1) * batch_size] = inn.forward(X_test_scaled[i_batch * batch_size: (i_batch+1) * batch_size])[0].detach().cpu().numpy()\n",
    "\n",
    "    for i, y_label in enumerate(['hosp', 'death']):\n",
    "        print(f'--- {y_label} ---')\n",
    "        evaluation_results[y_label].append(np.concatenate([1 - y_proba_pred[:, i].reshape(-1, 1), y_proba_pred[:, i].reshape(-1, 1)], axis=1))\n",
    "\n",
    "        print(f'binary cross-entropy: {np.round(log_loss(y_test[:, i], evaluation_results[y_label][-1][:, 1]), 4)}')\n",
    "        print(f'brier loss: {brier_score_loss(y_test[:, i], evaluation_results[y_label][-1][:, 1]).round(4)}')\n",
    "        print(f'accuracy: {accuracy_score(y_test[:, i], evaluation_results[y_label][-1][:, 1].round()).round(4)}')\n",
    "        print('confusion matrix:')\n",
    "        print(confusion_matrix(y_test[:, i], (evaluation_results[y_label][-1][:, 1] > 0.5).astype(int)))\n",
    "        print()\n",
    "        time.sleep(0.5)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1130/1130 [00:02<00:00, 527.13it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--- hosp ---\n",
      "binary cross-entropy: 0.2771\n",
      "brier loss: 0.067\n",
      "accuracy: 0.9192\n",
      "confusion matrix:\n",
      "[[526415  12607]\n",
      " [ 34116   5279]]\n",
      "\n",
      "--- death ---\n",
      "binary cross-entropy: 0.0679\n",
      "brier loss: 0.0125\n",
      "accuracy: 0.9858\n",
      "confusion matrix:\n",
      "[[568592   2107]\n",
      " [  6134   1584]]\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1130/1130 [00:02<00:00, 550.72it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--- hosp ---\n",
      "binary cross-entropy: 0.2229\n",
      "brier loss: 0.0584\n",
      "accuracy: 0.932\n",
      "confusion matrix:\n",
      "[[536576   2446]\n",
      " [ 36864   2531]]\n",
      "\n",
      "--- death ---\n",
      "binary cross-entropy: 0.0568\n",
      "brier loss: 0.0118\n",
      "accuracy: 0.987\n",
      "confusion matrix:\n",
      "[[569493   1206]\n",
      " [  6334   1384]]\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1130/1130 [00:01<00:00, 606.23it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--- hosp ---\n",
      "binary cross-entropy: 0.2129\n",
      "brier loss: 0.057\n",
      "accuracy: 0.9323\n",
      "confusion matrix:\n",
      "[[535849   3173]\n",
      " [ 35982   3413]]\n",
      "\n",
      "--- death ---\n",
      "binary cross-entropy: 0.072\n",
      "brier loss: 0.0134\n",
      "accuracy: 0.9843\n",
      "confusion matrix:\n",
      "[[567678   3021]\n",
      " [  6044   1674]]\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1130/1130 [00:01<00:00, 632.73it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--- hosp ---\n",
      "binary cross-entropy: 0.2395\n",
      "brier loss: 0.0611\n",
      "accuracy: 0.9265\n",
      "confusion matrix:\n",
      "[[530798   8224]\n",
      " [ 34297   5098]]\n",
      "\n",
      "--- death ---\n",
      "binary cross-entropy: 0.0646\n",
      "brier loss: 0.0108\n",
      "accuracy: 0.9881\n",
      "confusion matrix:\n",
      "[[570187    512]\n",
      " [  6357   1361]]\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1130/1130 [00:01<00:00, 631.23it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--- hosp ---\n",
      "binary cross-entropy: 0.2321\n",
      "brier loss: 0.0598\n",
      "accuracy: 0.9296\n",
      "confusion matrix:\n",
      "[[534499   4523]\n",
      " [ 36217   3178]]\n",
      "\n",
      "--- death ---\n",
      "binary cross-entropy: 0.0543\n",
      "brier loss: 0.0116\n",
      "accuracy: 0.9871\n",
      "confusion matrix:\n",
      "[[569584   1115]\n",
      " [  6341   1377]]\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "with open('../../evaluation_results/predictions/INN.pt', 'wb') as file:\n",
    "    pickle.dump(evaluation_results, file)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}